{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'artist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b0bc7c8541ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupBy\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from pandas.core.groupby.generic import (  # noqa: F401\n\u001b[1;32m      3\u001b[0m     SeriesGroupBy, DataFrameGroupBy, PanelGroupBy)\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mreorder_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     arrays_to_mgr, sanitize_index)\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconsole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_terminal_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# pylint: disable=E1101,E1103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/plotting/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     from pandas.plotting._converter import (\n\u001b[0m\u001b[1;32m     16\u001b[0m         register as register_matplotlib_converters)\n\u001b[1;32m     17\u001b[0m     from pandas.plotting._converter import (\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/pandas/plotting/_converter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelativedelta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelativedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFormatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLocator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnonsingular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m     \u001b[0mrcParamsOrig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRcParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m     rcParamsDefault = RcParams([(key, default) for key, (default, converter) in\n\u001b[1;32m   1113\u001b[0m                                 \u001b[0mdefaultParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcsetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'artist'"
     ]
    }
   ],
   "source": [
    "# First, Please turn on the GPU on Kaggle.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if_gpu = torch.cuda.is_available()\n",
    "print(\"GPU is on?\", if_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "274bd8362a79bb5bc280afb0bc8d6095a72f1124"
   },
   "outputs": [],
   "source": [
    "# Show some information of Kaggle's input folder.\n",
    "\n",
    "print(os.listdir(\"../\"))\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/train\"))\n",
    "print(os.listdir(\"../input/test\")[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebc31b6ff881320ae3617ea5902fadb68b13d676"
   },
   "outputs": [],
   "source": [
    "# ImageFolder() needs subfolders.\n",
    "# Copy test images of input to temporary folder to avoid train images.\n",
    "\n",
    "def copytree_and_overwrite(from_path, to_path):\n",
    "    if os.path.exists(to_path):\n",
    "        shutil.rmtree(to_path)\n",
    "    shutil.copytree(from_path, to_path)\n",
    "    return True\n",
    "\n",
    "copytree_and_overwrite(\"../input/test\", \"../working/tmp/test/test_images\")\n",
    "\n",
    "print(os.listdir(\"../working/tmp/test/test_images\")[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bfc4dfd2fec1727bc9d50bdd21cefd5afbf8f04"
   },
   "outputs": [],
   "source": [
    "# Read and resize images to [224, 224].\n",
    "\n",
    "def read_image_folder(resize_shape, image_folder):\n",
    "    resize = torchvision.transforms.Resize(resize_shape)\n",
    "    image_folder = ImageFolder(image_folder, transform=resize)\n",
    "\n",
    "    idx_to_class = {value: key for key, value in image_folder.class_to_idx.items()}\n",
    "    image_paths = [item[0] for item in image_folder.imgs]\n",
    "\n",
    "    image_shape = np.array(image_folder[0][0]).shape\n",
    "    data_length = len(image_folder)\n",
    "\n",
    "    data_shape = list(image_shape)\n",
    "    data_shape.insert(0, data_length)\n",
    "\n",
    "    data = np.zeros(data_shape, dtype=np.uint8)\n",
    "    labels = np.zeros([data_length], dtype=np.int64)\n",
    "\n",
    "    i = 0\n",
    "    for image, label in tqdm(image_folder, desc=\"Reading Images\"):\n",
    "        data[i] = np.array(image)\n",
    "        labels[i] = label\n",
    "        i += 1\n",
    "\n",
    "    data_dict = {\"data\": data, \"labels\": labels, 'data_shape': image_shape}\n",
    "    info_dict = {\"label_names\": idx_to_class, \"file_paths\": image_paths}\n",
    "\n",
    "    return data_dict, info_dict\n",
    "\n",
    "train_dict, train_info_dict = read_image_folder((224,224),\"../input/train\")\n",
    "test_dict, test_info_dict = read_image_folder((224,224),\"../working/tmp/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Show one of train and test.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(train_dict[\"data\"][800])\n",
    "plt.figure()\n",
    "plt.imshow(test_dict[\"data\"][600])\n",
    "print(\"iamge shape =\", train_dict[\"data\"][300].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e00dcaa4eff775efc4af2ef4465a813782e005e"
   },
   "outputs": [],
   "source": [
    "# Define a dataset\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.to_tensor(self.x_data[index]), self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cfa12634c04aacf9278cfdc55bbbfb697f4ee4ea"
   },
   "outputs": [],
   "source": [
    "# Note that torchvision.transforms.ToTensor() will\n",
    "# Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "# [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "\n",
    "whole_dataset = ImageDataset(train_dict[\"data\"], train_dict[\"labels\"])\n",
    "\n",
    "print(whole_dataset[0][0].shape)\n",
    "print(whole_dataset[4610])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fb8c6c9e9827f96b669a15ae302d785e926f78a"
   },
   "outputs": [],
   "source": [
    "# subset the whole train set for accuracy check while training.\n",
    "\n",
    "def array_random_pick(array, pick_num):\n",
    "    index = np.arange(len(array))\n",
    "    pick = np.random.choice(len(array), pick_num, replace=False)\n",
    "    unpick = np.equal(np.in1d(index, pick), False)\n",
    "    return array[unpick], array[pick]\n",
    "\n",
    "train_mask, valid_mask = array_random_pick(np.arange(len(whole_dataset)), 500)\n",
    "\n",
    "train_set = torch.utils.data.Subset(whole_dataset, train_mask)\n",
    "valid_set = torch.utils.data.Subset(whole_dataset, valid_mask)\n",
    "\n",
    "print(len(train_set),len(valid_set))\n",
    "print(train_set[4010])\n",
    "print(valid_set[401])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a89038117143726d2ff7161b87d4ae4d4f5457f7"
   },
   "outputs": [],
   "source": [
    "# Use DataLoader to group data batchs. Here use size 4 for a batch.\n",
    "# DataLoader will return a iterator.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=5)\n",
    "load_iter = iter(train_loader)\n",
    "one_batch_x, one_batch_y = next(load_iter)\n",
    "\n",
    "print(one_batch_y)\n",
    "print(one_batch_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2286cbf5bd7e89df03e328476f4eb9cfe10abd44"
   },
   "outputs": [],
   "source": [
    "# Use PyTorch's built-in model to generate AlexNet with classes 12.\n",
    "# With input data of size [4, 3, 224, 224], AlexNet will output data of size [4, 12].\n",
    "\n",
    "alex = torchvision.models.AlexNet(num_classes = 12)\n",
    "alex_out = alex(one_batch_x)\n",
    "print(alex_out.shape)\n",
    "print(alex_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f29d1a5d937d53668b591efbccf2f81fbf44f927"
   },
   "outputs": [],
   "source": [
    "# We use the max index of alex_out to\n",
    "# evaluate the accuracy of model predict.\n",
    "# Now the accuracy is zero before model train.\n",
    "\n",
    "predict = torch.argmax(alex_out, dim = 1)\n",
    "compare = predict == one_batch_y\n",
    "accuracy = compare.sum() / len(predict)\n",
    "\n",
    "print(predict)\n",
    "print(one_batch_y)\n",
    "print(compare)\n",
    "print(\"accuracy =\", accuracy.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edd33efd58c8b8ae2353002acd8006b1db7162ff"
   },
   "outputs": [],
   "source": [
    "# define a base utility to train a net.\n",
    "\n",
    "class BaseNetPyTorch:\n",
    "    def __init__(self):\n",
    "        self.train_loader = None\n",
    "        self.sub_train_loader = None\n",
    "        self.valid_loader = None\n",
    "\n",
    "        self.model = None\n",
    "        self.optimize_method = None\n",
    "        self.loss_function = None\n",
    "\n",
    "        if_gpu = torch.cuda.is_available()\n",
    "        self.device_gpu = torch.device(\"cuda:0\" if if_gpu else \"cpu\")\n",
    "\n",
    "    def train_loss(self):\n",
    "        # \"training\" mode for Dropout etc.\n",
    "        self.model.train()\n",
    "\n",
    "        train_loss = None\n",
    "        for (x, y) in self.train_loader:\n",
    "            x_gpu = x.to(self.device_gpu)\n",
    "            y_gpu = y.long().to(self.device_gpu)\n",
    "\n",
    "            predict = self.model(x_gpu)\n",
    "            train_loss = self.loss_function(predict, y_gpu)\n",
    "\n",
    "            self.optimize_method.zero_grad()\n",
    "            train_loss.backward()\n",
    "            self.optimize_method.step()\n",
    "        return train_loss\n",
    "\n",
    "    def predict_index(self, check_loader):\n",
    "        predict_list = []\n",
    "        for x, y in check_loader:\n",
    "            x_gpu = x.to(self.device_gpu)\n",
    "            predict = self.model(x_gpu)\n",
    "            max_index = torch.argmax(predict, dim=1)\n",
    "            predict_list += max_index.cpu().data.numpy().tolist()\n",
    "        return predict_list\n",
    "\n",
    "    def check_accuracy(self, check_set):\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        # \"test\" mode for Dropout etc.\n",
    "        self.model.eval()\n",
    "        for x, y in check_set:\n",
    "            x_gpu = x.to(self.device_gpu)\n",
    "            y_gpu = y.to(self.device_gpu)\n",
    "\n",
    "            predict = self.model(x_gpu)\n",
    "            max_index = torch.argmax(predict, dim=1)\n",
    "\n",
    "            num_correct += (max_index == y_gpu).sum()\n",
    "            num_samples += max_index.shape[0]\n",
    "\n",
    "        accuracy = float(num_correct) / float(num_samples)\n",
    "        return num_correct, num_samples, accuracy\n",
    "\n",
    "    def train(self, num_epochs=1):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"self.model is None! Please assign it.\")\n",
    "        if self.optimize_method is None:\n",
    "            raise ValueError(\"self.optimize_method is None! Please assign it.\")\n",
    "        if self.loss_function is None:\n",
    "            raise ValueError(\"self.loss_function is None! Please assign it.\")\n",
    "\n",
    "        print(\"begin training, length_of_one_mini_batch :\", len(self.train_loader))\n",
    "\n",
    "        self.model = self.model.to(self.device_gpu)\n",
    "\n",
    "        train_time = time.time()\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "\n",
    "            loss = self.train_loss()\n",
    "            loss_time = time.time()\n",
    "\n",
    "            train_correct, train_samples, train_acc = self.check_accuracy(self.sub_train_loader)\n",
    "            train_acc_time = time.time()\n",
    "\n",
    "            valid_correct, valid_samples, valid_acc = self.check_accuracy(self.valid_loader)\n",
    "            valid_acc_time = time.time()\n",
    "\n",
    "            epoch_time = time.time()\n",
    "\n",
    "            print('epoch:%d/%d' % (epoch + 1, num_epochs), end=\" \")\n",
    "            print('loss:%.4f|%ds' % (loss.data, (loss_time - epoch_start)), end=\" \")\n",
    "            print('train_acc:(%d/%d %0.2f%%)|%ds' %\n",
    "                  (train_correct, train_samples, 100 * train_acc, train_acc_time - loss_time), end=' ')\n",
    "            print('valid_acc:(%d/%d %0.2f%%)|%ds' %\n",
    "                  (valid_correct, valid_samples, 100 * valid_acc, (valid_acc_time - train_acc_time)), end=' ')\n",
    "            print(\"take:%dmin remain:%dmin\" %\n",
    "                  ((epoch_time - train_time) / 60, (epoch_time - epoch_start) * (num_epochs - epoch) / 60))\n",
    "\n",
    "            if (train_acc - 0.3 > valid_acc) and (train_acc > 0.5):\n",
    "                print(\"Model Overfit 30.00%, stopped.\")\n",
    "                return True\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f4c230b075389839555b06f1d01e2d8331ce565"
   },
   "outputs": [],
   "source": [
    "# It is very important to turn on shuffle=True of training set\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=40, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=40)\n",
    "\n",
    "net = BaseNetPyTorch()\n",
    "net.model = torchvision.models.AlexNet(num_classes=12)\n",
    "net.optimize_method = torch.optim.Adam(net.model.parameters(), lr=0.0001)\n",
    "net.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net.train_loader = train_loader\n",
    "net.sub_train_loader = train_loader\n",
    "net.valid_loader = valid_loader\n",
    "\n",
    "net.train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a8dab7d12afe2eb75029afb9d25a65d05fd7938"
   },
   "outputs": [],
   "source": [
    "# predict test file labels\n",
    "\n",
    "test_set = ImageDataset(test_dict[\"data\"], test_dict[\"labels\"])\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=40)\n",
    "label_names = train_info_dict[\"label_names\"]\n",
    "\n",
    "test_predict = net.predict_index(test_loader)\n",
    "predict_names = [label_names[i] for i in test_predict]\n",
    "\n",
    "print(test_predict[:10])\n",
    "print(predict_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30f6eba1220e20a277b14b609fe7e1c12473f936"
   },
   "outputs": [],
   "source": [
    "# classify test_files to different sub_folders\n",
    "\n",
    "test_file_paths = test_info_dict[\"file_paths\"]\n",
    "save_folder = \"../working/tmp/predict\"\n",
    "\n",
    "def make_dirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def copy2sub_folders(source_file_paths, sub_folder_names, to_folder):\n",
    "    for i in tqdm(range(len(source_file_paths))):\n",
    "        file_dir = os.path.join(to_folder, sub_folder_names[i])\n",
    "        make_dirs(file_dir)\n",
    "        shutil.copy2(source_file_paths[i], file_dir)\n",
    "        \n",
    "copy2sub_folders(test_file_paths, predict_names, save_folder)\n",
    "\n",
    "print(os.listdir(\"../working/tmp/predict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18fe1efed080a581234d5bf924831077c7084f22"
   },
   "outputs": [],
   "source": [
    "# Create a predict submission file.\n",
    "\n",
    "def folder_file_info(root):\n",
    "    folder_file_list = []\n",
    "    path_dirs = os.listdir(root)\n",
    "    for folder in path_dirs:\n",
    "        dir_files = os.listdir(os.path.join(root, folder))\n",
    "        for file_name in dir_files:\n",
    "            folder_file_list.append([file_name, folder])\n",
    "    return folder_file_list\n",
    "\n",
    "\n",
    "file_predict_table = folder_file_info(\"../working/tmp/predict\")\n",
    "df = pd.DataFrame(file_predict_table, columns=['file', 'species'])\n",
    "df.to_csv(\"predict_submission.csv\", index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52c6ab3e69fdf5a94ec5afea2de811eccaba49db"
   },
   "outputs": [],
   "source": [
    "# delect temporary working folder before Kaggle Commit.\n",
    "if os.path.exists(\"../working/tmp\"):\n",
    "    shutil.rmtree(\"../working/tmp\")\n",
    "\n",
    "os.listdir(\"../working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2f4f91c1480071f95e8b8bb0729cc24e4f15668"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
